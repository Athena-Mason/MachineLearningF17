{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import idx2numpy\n",
    "\n",
    "X_train = idx2numpy.convert_from_file('train-images-idx3-ubyte')\n",
    "y_train = idx2numpy.convert_from_file('train-labels-idx1-ubyte')\n",
    "X_test = idx2numpy.convert_from_file('t10k-images-idx3-ubyte')\n",
    "y_test = idx2numpy.convert_from_file('t10k-labels-idx1-ubyte')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# flatten the image.\n",
    "# turn the data into a (samples, feature) matrix:\n",
    "X_train = X_train.reshape((len(X_train), -1))\n",
    "X_test = X_test.reshape((len(X_test), -1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Models\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 958    0    0    4    0    3    5    2    6    2]\n",
      " [   0 1116    3    1    0    1    4    1    8    1]\n",
      " [   8   12  906   18    9    5   10   11   50    3]\n",
      " [   3    0   19  916    2   23    5   11   24    7]\n",
      " [   1    2    5    3  910    0   11    2   10   38]\n",
      " [  11    2    1   40   10  756   16    8   40    8]\n",
      " [   7    3    7    2    4   17  911    1    6    0]\n",
      " [   3    6   24    4    7    1    1  946    5   31]\n",
      " [   9   15    7   22   11   26    7   12  854   11]\n",
      " [   9    6    2   13   30    4    0   26   16  903]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.93      0.88      0.90      1032\n",
      "          3       0.90      0.91      0.90      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.90      0.85      0.88       892\n",
      "          6       0.94      0.95      0.95       958\n",
      "          7       0.93      0.92      0.92      1028\n",
      "          8       0.84      0.88      0.86       974\n",
      "          9       0.90      0.89      0.90      1009\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n",
      "Accuracy\n",
      "0.9176\n"
     ]
    }
   ],
   "source": [
    "# create logistic regression object\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# test values\n",
    "y_predicted = logreg.predict(X_test)\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "classification_report = classification_report(y_test, y_predicted)\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hidden Layer MLP (50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 877    0    7    2    0   60   10    1   23    0]\n",
      " [   0 1094   12    3    0    1    2    4   18    1]\n",
      " [   5    0  926    4   10    3   13    5   59    7]\n",
      " [   0    1   91  817    0   41    1   12   36   11]\n",
      " [   1    0    2    1  654    2   11    3    8  300]\n",
      " [   5    1    4   94    3  641    9    4  113   18]\n",
      " [   5    3    5    2   21   11  882    0   28    1]\n",
      " [   1    4   74    5    2    2    0  891    8   41]\n",
      " [   4    1   56   18    1   23    6    4  837   24]\n",
      " [   3    6    1   14   19    7    0   13   18  928]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.89      0.93       980\n",
      "          1       0.99      0.96      0.97      1135\n",
      "          2       0.79      0.90      0.84      1032\n",
      "          3       0.85      0.81      0.83      1010\n",
      "          4       0.92      0.67      0.77       982\n",
      "          5       0.81      0.72      0.76       892\n",
      "          6       0.94      0.92      0.93       958\n",
      "          7       0.95      0.87      0.91      1028\n",
      "          8       0.73      0.86      0.79       974\n",
      "          9       0.70      0.92      0.79      1009\n",
      "\n",
      "avg / total       0.87      0.85      0.86     10000\n",
      "\n",
      "Accuracy\n",
      "0.8547\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#create and fit mlp\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# test values\n",
    "y_predicted = mlp.predict(X_test)\n",
    "# print confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "classification_report = classification_report(y_test, y_predicted)\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hidden Layer MLP (100 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 942    1    6    2    0    5   12    6    6    0]\n",
      " [   0 1109    3    3    0    1    2    1   15    1]\n",
      " [   5    3  976   15    7    1    4   10    8    3]\n",
      " [   1    3   13  945    0   16    1    3   21    7]\n",
      " [   0    2   13    0  922    1    4    2    6   32]\n",
      " [   4    1    1   27    2  818   13    2   18    6]\n",
      " [   5    4    5    0    3   10  923    2    6    0]\n",
      " [   1    4   20    5    6    4    0  956    4   28]\n",
      " [   4    0    7    8    8   10    4    4  919   10]\n",
      " [   4    5    3    8   27    6    0    6   14  936]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.93      0.95      0.94      1032\n",
      "          3       0.93      0.94      0.93      1010\n",
      "          4       0.95      0.94      0.94       982\n",
      "          5       0.94      0.92      0.93       892\n",
      "          6       0.96      0.96      0.96       958\n",
      "          7       0.96      0.93      0.95      1028\n",
      "          8       0.90      0.94      0.92       974\n",
      "          9       0.91      0.93      0.92      1009\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10000\n",
      "\n",
      "Accuracy\n",
      "0.9446\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#create and fit mlp\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# test values\n",
    "y_predicted = mlp.predict(X_test)\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "classification_report = classification_report(y_test, y_predicted)\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hidden Layer MLP (400 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 965    0    2    2    1    2    3    2    2    1]\n",
      " [   0 1121    3    2    0    2    2    3    2    0]\n",
      " [   5    3  994    6    4    0    2    6   10    2]\n",
      " [   1    0    3  981    0    8    0    2    5   10]\n",
      " [   1    0    5    0  952    1    2    4    2   15]\n",
      " [   4    0    2   15    2  849    8    1    4    7]\n",
      " [   4    2    2    1    6   11  927    1    4    0]\n",
      " [   1    4   10    3    3    0    0  991    3   13]\n",
      " [   2    0    3   13    4    7    5    3  930    7]\n",
      " [   0    4    1    2   10    5    2    8    5  972]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.97      0.96      0.97      1032\n",
      "          3       0.96      0.97      0.96      1010\n",
      "          4       0.97      0.97      0.97       982\n",
      "          5       0.96      0.95      0.96       892\n",
      "          6       0.97      0.97      0.97       958\n",
      "          7       0.97      0.96      0.97      1028\n",
      "          8       0.96      0.95      0.96       974\n",
      "          9       0.95      0.96      0.95      1009\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "Accuracy\n",
      "0.9682\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#create and fit mlp\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(400), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# test values\n",
    "y_predicted = mlp.predict(X_test)\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "classification_report = classification_report(y_test, y_predicted)\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Hidden Layer MLP (100 and 50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 964    0    3    0    2    2    1    5    2    1]\n",
      " [   0 1120    6    1    0    1    2    0    2    3]\n",
      " [   7    1  990   17    3    1    2    5    6    0]\n",
      " [   0    1    9  976    1    8    0    3    7    5]\n",
      " [   1    0    7    0  937    1    8    0    3   25]\n",
      " [   4    0    1   12    0  857    5    0    7    6]\n",
      " [   5    2    0    0    7    4  936    0    4    0]\n",
      " [   2    3   10    2    0    0    0  994    4   13]\n",
      " [   5    1    6    7    3    8    2    7  933    2]\n",
      " [   3    3    0    7   18   13    1   10    4  950]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.96      0.96      0.96      1032\n",
      "          3       0.95      0.97      0.96      1010\n",
      "          4       0.96      0.95      0.96       982\n",
      "          5       0.96      0.96      0.96       892\n",
      "          6       0.98      0.98      0.98       958\n",
      "          7       0.97      0.97      0.97      1028\n",
      "          8       0.96      0.96      0.96       974\n",
      "          9       0.95      0.94      0.94      1009\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "Accuracy\n",
      "0.9657\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#create and fit mlp\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 50), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# test values\n",
    "y_predicted = mlp.predict(X_test)\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "classification_report = classification_report(y_test, y_predicted)\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "### 1. Which model gives the best accuracy? Which the best overall F1 score?\n",
    "The model with the highest accuracy is the one-hidden layer MLP with 400 nodes, with 96.8% accuracy. The two-hidden layer MLP model is a close second, with 96.6%. Both these models are tied for best overall F1 score, with a score of .97. The 100-node single-hidden layer MLP is close, with an F1 score of .94.\n",
    "### 2. Which model gives the worst accuracy? Which the worst overall F1 score?\n",
    "The model with the lowest accuracy is the one-hidden layer MLP with 50 nodes, with 85.5% accuracy. This is significantly worse than the next-worse model, the logistic regression model, which has an accuracy of 91.8%. The 50-node single-hidden layer MLP also has the lowest F1 score of .85. The next-worse F1 score, which belongs to the logistic regression model, is .92.\n",
    "### 3. What is the shape of the training set? How many nodes are in the input layer of the network?\n",
    "The shape of the training set is 60,000 x 784. There are 784 nodes in the input layer of the network, because that is the number of parameters for each item in the set.\n",
    "### 4. Look the documentation for MLPClassifier. Why are we using lbfgs solver? Look up l-bfgs and provide a description of what it does.\n",
    "In the MLPClassifier documentation, it states that the lbfgs solver is \"an optimizer in the family of quasi-Newton methods.\" In small datasets, it converges faster than the default solver, which is why we're using it for this set. \n",
    "\n",
    "More specifically, limited-memory BFGS approximates the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm. As a quasi-Newton method, the BFGS algorithm replaces the exact inverse Hessian matrix used in Newton's method with an approximation. L-BFGS stores a less dense approximation of the approximated inverse Hessian matrix than the original BFGS algorithm, which results in a smaller memory requirement and is therefore better suited to problems with large numbers of variables.\n",
    "\n",
    "L-BFGS starts with an initial estimation of the best value, and then iterately improves that estimate. The search direction is equal to the inverse Hessian matrix * the current derivative.\n",
    "\n",
    "(sources:   http://aria42.com/blog/2014/12/understanding-lbfgs, https://en.wikipedia.org/wiki/Limited-memory_BFGS, https://en.wikipedia.org/wiki/Quasi-Newton_method)\n",
    "### 5. Why do you think the best/worst networks are that way?\n",
    "Intuitively, it makes sense that the more nodes there are in a neural network, the more the network can learn about the training set, which would make it more accurate at predicting the results from that dataset (although there is always the risk of overtraining). The 400-node single-hidden-layer network and the two-hidden-layer network both have more nodes overall than the other MLPs. However, the two-hidden-layer MLP has significantly fewer total nodes (150) than the 400-node network with a relatively small (less than 0.3%) reduction in accuracy. This would seem to indicate that adding depth is more effective than adding width. In the interest of making a fair comparison, I ran a one-hidden-layer MLP with 150 nodes (the same total number of nodes as the two-hidden-layer MLP) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 955    0    4    1    3    4    3    3    5    2]\n",
      " [   0 1114    3    3    0    2    3    2    8    0]\n",
      " [  10    5  969   10    2    1    7   10   16    2]\n",
      " [   1    1   12  965    0    9    2    6   11    3]\n",
      " [   0    3    4    0  936    0    9    4    4   22]\n",
      " [   4    1    1   17    2  841    9    2   11    4]\n",
      " [   6    2    2    1    8    6  928    0    5    0]\n",
      " [   2    5   16    8    7    0    0  969    4   17]\n",
      " [   5    2   13   13    6    7    6    8  911    3]\n",
      " [   3    5    1    8   17    7    2   15   10  941]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.95      0.94      0.94      1032\n",
      "          3       0.94      0.96      0.95      1010\n",
      "          4       0.95      0.95      0.95       982\n",
      "          5       0.96      0.94      0.95       892\n",
      "          6       0.96      0.97      0.96       958\n",
      "          7       0.95      0.94      0.95      1028\n",
      "          8       0.92      0.94      0.93       974\n",
      "          9       0.95      0.93      0.94      1009\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10000\n",
      "\n",
      "Accuracy\n",
      "0.9529\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#create and fit mlp\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# test values\n",
    "y_predicted = mlp.predict(X_test)\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "classification_report = classification_report(y_test, y_predicted)\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, this MLP was better than the 50-node (85.5% accuracy) and 100-node (94.4%) MLPs, but worse than the 400-node (96.8%) and two-hidden-layer (96.6%) MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "### 6. Experiment and try to create a better performing network using tensorflow. Explain what you tried and document the results.\n",
    "#### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# using example code from https://www.tensorflow.org/get_started/mnist/beginners\n",
    "# reimport data for use in tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# define model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# cross-entropy\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "# learning rate at 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 1000 times\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, I built and trained the model using the code directly from the tensorflow beginner MNIST tutorial, using a learning rate of 0.5, with a batch size of 100, and running the training step 1000 times. These were the default values in the tutorial. The model is evaluated below using the evaluation method in the tensorflow tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9071\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get more information on the results of the model, I imported the sklearn confusion matrix, classification report, and the accuracy score (it's worth noting that the sklearn accuracy score and the accuracy from the tensorflow tutorial come up with the same result). I will be using the sklearn metrics to judge the rest of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 961    0    3    1    0    1    7    1    6    0]\n",
      " [   0 1099    3    5    1    2    5    1   19    0]\n",
      " [  10    0  903   16   15    1   16   19   43    9]\n",
      " [   3    0   23  904    1   30    5   12   22   10]\n",
      " [   2    4    5    0  908    1   11    1   10   40]\n",
      " [  15    5    5   42   20  713   21   14   48    9]\n",
      " [  18    3    4    2   10   16  899    1    5    0]\n",
      " [   3   20   33    3   13    0    0  921    5   30]\n",
      " [   7    8   10   15    7   20   13   12  872   10]\n",
      " [  11    5    4    9   44   18    0   16   11  891]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.96       980\n",
      "          1       0.96      0.97      0.96      1135\n",
      "          2       0.91      0.88      0.89      1032\n",
      "          3       0.91      0.90      0.90      1010\n",
      "          4       0.89      0.92      0.91       982\n",
      "          5       0.89      0.80      0.84       892\n",
      "          6       0.92      0.94      0.93       958\n",
      "          7       0.92      0.90      0.91      1028\n",
      "          8       0.84      0.90      0.87       974\n",
      "          9       0.89      0.88      0.89      1009\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n",
      "Accuracy\n",
      "0.9071\n"
     ]
    }
   ],
   "source": [
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the variables in isolation\n",
    "For the models below, I tested some different values for the learning rate, batch size, and number of batches that are run. For the first set of models, I adjusted one of these at a time while leaving the others as the default values.\n",
    "\n",
    "##### Adjusting Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 950    0    3    1    1    0   16    1    8    0]\n",
      " [   0 1106    2    4    1    0    5    1   16    0]\n",
      " [  13    8  867   19   21    0   28   23   44    9]\n",
      " [   4    2   25  902    1    0   10   17   31   18]\n",
      " [   1    8    5    0  883    0   15    1    6   63]\n",
      " [  82   26    4  295   67    0   49   35  287   47]\n",
      " [  22    3    5    2    7    0  908    0   11    0]\n",
      " [   3   28   33    1   12    0    4  900    3   44]\n",
      " [   8   14   14   34   12    0   18   13  842   19]\n",
      " [  18   10    7   14   52    0    3   24   14  867]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       980\n",
      "          1       0.92      0.97      0.95      1135\n",
      "          2       0.90      0.84      0.87      1032\n",
      "          3       0.71      0.89      0.79      1010\n",
      "          4       0.84      0.90      0.87       982\n",
      "          5       0.00      0.00      0.00       892\n",
      "          6       0.86      0.95      0.90       958\n",
      "          7       0.89      0.88      0.88      1028\n",
      "          8       0.67      0.86      0.75       974\n",
      "          9       0.81      0.86      0.84      1009\n",
      "\n",
      "avg / total       0.76      0.82      0.79     10000\n",
      "\n",
      "Accuracy\n",
      "0.8225\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.1\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    2    1    0    0    6    1    8    0]\n",
      " [   0 1107    2    4    1    0    4    1   16    0]\n",
      " [  13    1  899   18   14    0   18   23   37    9]\n",
      " [   6    0   26  898    1   25    5   16   21   12]\n",
      " [   2    5    5    0  896    1   12    1    9   51]\n",
      " [  29   12    7   77   20  640   24   16   57   10]\n",
      " [  19    3    4    2    7   16  901    0    6    0]\n",
      " [   4   20   36    2   12    0    1  919    5   29]\n",
      " [  10   10   13   24   11   21   16   16  838   15]\n",
      " [  14    7    7   13   44   13    1   22    8  880]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       980\n",
      "          1       0.95      0.98      0.96      1135\n",
      "          2       0.90      0.87      0.88      1032\n",
      "          3       0.86      0.89      0.88      1010\n",
      "          4       0.89      0.91      0.90       982\n",
      "          5       0.89      0.72      0.80       892\n",
      "          6       0.91      0.94      0.93       958\n",
      "          7       0.91      0.89      0.90      1028\n",
      "          8       0.83      0.86      0.85       974\n",
      "          9       0.87      0.87      0.87      1009\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10000\n",
      "\n",
      "Accuracy\n",
      "0.894\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.25\n",
    "train_step = tf.train.GradientDescentOptimizer(0.25).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 1000 times\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 964    0    0    2    1    2    8    1    2    0]\n",
      " [   0 1103    2    6    1    1    5    2   15    0]\n",
      " [  14    2  884   20   15    0   17   26   41   13]\n",
      " [   4    1   16  925    1   20    4   10   17   12]\n",
      " [   3    2    3    0  899    0   13    1    5   56]\n",
      " [  17    3    2   46   15  726   24   10   38   11]\n",
      " [  18    3    4    3   11   12  905    1    1    0]\n",
      " [   4   17   23    4   11    0    0  927    3   39]\n",
      " [  10    9    6   27    8   17   15   16  853   13]\n",
      " [  14    5    3   11   25   14    1   13    7  916]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       980\n",
      "          1       0.96      0.97      0.97      1135\n",
      "          2       0.94      0.86      0.90      1032\n",
      "          3       0.89      0.92      0.90      1010\n",
      "          4       0.91      0.92      0.91       982\n",
      "          5       0.92      0.81      0.86       892\n",
      "          6       0.91      0.94      0.93       958\n",
      "          7       0.92      0.90      0.91      1028\n",
      "          8       0.87      0.88      0.87       974\n",
      "          9       0.86      0.91      0.89      1009\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n",
      "Accuracy\n",
      "0.9102\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.75\n",
    "train_step = tf.train.GradientDescentOptimizer(0.75).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 1000 times\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    1    1    1    2   10    1    2    0]\n",
      " [   0 1106    3    5    0    2    5    1   13    0]\n",
      " [  14    0  909   14   12    0   20   16   38    9]\n",
      " [   4    0   23  910    1   27    5    8   19   13]\n",
      " [   2    2    3    0  895    0   17    2    6   55]\n",
      " [  15    3    3   37   14  742   21    8   39   10]\n",
      " [  14    3    4    2    9   14  911    0    1    0]\n",
      " [   5   18   31    3   11    0    0  914    4   42]\n",
      " [   7    9    6   18    8   16   14   13  874    9]\n",
      " [   9    6    3    9   23   16    1    7    9  926]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.96       980\n",
      "          1       0.96      0.97      0.97      1135\n",
      "          2       0.92      0.88      0.90      1032\n",
      "          3       0.91      0.90      0.91      1010\n",
      "          4       0.92      0.91      0.92       982\n",
      "          5       0.91      0.83      0.87       892\n",
      "          6       0.91      0.95      0.93       958\n",
      "          7       0.94      0.89      0.91      1028\n",
      "          8       0.87      0.90      0.88       974\n",
      "          9       0.87      0.92      0.89      1009\n",
      "\n",
      "avg / total       0.92      0.91      0.91     10000\n",
      "\n",
      "Accuracy\n",
      "0.9149\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.75\n",
    "train_step = tf.train.GradientDescentOptimizer(1).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 1000 times\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the learning rate in isolation seems to result in worse results as the size of the learning rate decreases. This makes sense, as a smaller learning rate means it will take longer to reach the minimum, so the training could be terminating before the estimated minimum is reached.\n",
    "##### Adjusting Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 964    0    1    2    1    1    6    1    4    0]\n",
      " [   0 1100    2    6    1    2    5    1   18    0]\n",
      " [  13    0  893   18   15    0   17   24   42   10]\n",
      " [   4    0   24  900    1   28    5   15   22   11]\n",
      " [   3    4    4    0  911    1   11    1    9   38]\n",
      " [  18    5    4   38   19  721   23   11   44    9]\n",
      " [  18    3    4    2    9   16  900    1    5    0]\n",
      " [   4   20   26    2   12    0    0  931    5   28]\n",
      " [   9    9   10   18    8   16   13   17  866    8]\n",
      " [  12    7    3    9   45   18    1   17    8  889]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       980\n",
      "          1       0.96      0.97      0.96      1135\n",
      "          2       0.92      0.87      0.89      1032\n",
      "          3       0.90      0.89      0.90      1010\n",
      "          4       0.89      0.93      0.91       982\n",
      "          5       0.90      0.81      0.85       892\n",
      "          6       0.92      0.94      0.93       958\n",
      "          7       0.91      0.91      0.91      1028\n",
      "          8       0.85      0.89      0.87       974\n",
      "          9       0.90      0.88      0.89      1009\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n",
      "Accuracy\n",
      "0.9075\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 961    0    1    0    1    1    9    2    5    0]\n",
      " [   0 1102    1    6    1    0    6    2   16    1]\n",
      " [  18    1  849   35   14    0   27   29   43   16]\n",
      " [   4    0   14  904    1   29    6   19   13   20]\n",
      " [   1    5    3    0  865    0   19    1    5   83]\n",
      " [  19    5    2   62   25  657   34   14   61   13]\n",
      " [  16    3    4    3    8    7  915    0    2    0]\n",
      " [   4   17   19    3   12    0    2  917    5   49]\n",
      " [  14   10    7   27   13   13   20   17  821   32]\n",
      " [  15    6    3   10   33    6    2    9    6  919]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95       980\n",
      "          1       0.96      0.97      0.96      1135\n",
      "          2       0.94      0.82      0.88      1032\n",
      "          3       0.86      0.90      0.88      1010\n",
      "          4       0.89      0.88      0.88       982\n",
      "          5       0.92      0.74      0.82       892\n",
      "          6       0.88      0.96      0.92       958\n",
      "          7       0.91      0.89      0.90      1028\n",
      "          8       0.84      0.84      0.84       974\n",
      "          9       0.81      0.91      0.86      1009\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10000\n",
      "\n",
      "Accuracy\n",
      "0.891\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(10)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    1    2    1    2    8    1    3    0]\n",
      " [   0 1105    1    6    1    2    5    1   14    0]\n",
      " [  15    5  882   17   17    0   20   25   39   12]\n",
      " [   3    1   15  905    1   29    6   17   21   12]\n",
      " [   1    4    3    0  907    1   13    1    9   43]\n",
      " [  20    5    2   38   19  720   26   11   42    9]\n",
      " [  15    3    4    2   10   15  906    1    2    0]\n",
      " [   4   21   25    3   13    0    0  929    2   31]\n",
      " [  11    9    7   23    9   18   16   18  850   13]\n",
      " [  13    8    3    9   40   19    1   20    5  891]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       980\n",
      "          1       0.95      0.97      0.96      1135\n",
      "          2       0.94      0.85      0.89      1032\n",
      "          3       0.90      0.90      0.90      1010\n",
      "          4       0.89      0.92      0.91       982\n",
      "          5       0.89      0.81      0.85       892\n",
      "          6       0.91      0.95      0.92       958\n",
      "          7       0.91      0.90      0.91      1028\n",
      "          8       0.86      0.87      0.87       974\n",
      "          9       0.88      0.88      0.88      1009\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n",
      "Accuracy\n",
      "0.9057\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(50)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the batch size alone seems to have a minimal effect on the accuracy of the model.\n",
    "\n",
    "##### Adjusting Number of Batches Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 963    0    2    2    0    2    9    1    1    0]\n",
      " [   0 1111    3    4    0    2    4    2    9    0]\n",
      " [  14    1  922   10   15    2   14   14   32    8]\n",
      " [   3    0   24  923    1   19    3   10   18    9]\n",
      " [   2    3    5    0  915    0   13    2    5   37]\n",
      " [  11    3    6   38   12  760   14   10   30    8]\n",
      " [  11    3    4    2    7   10  917    1    3    0]\n",
      " [   3    9   28    4    8    0    0  951    4   21]\n",
      " [   4    5    5   16    8   20   11   14  889    2]\n",
      " [  12    6    3   11   23   13    0   16   10  915]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.97      0.98      0.98      1135\n",
      "          2       0.92      0.89      0.91      1032\n",
      "          3       0.91      0.91      0.91      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.92      0.85      0.88       892\n",
      "          6       0.93      0.96      0.94       958\n",
      "          7       0.93      0.93      0.93      1028\n",
      "          8       0.89      0.91      0.90       974\n",
      "          9       0.92      0.91      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9266\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train\n",
    "for _ in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 946    0    3    1    0    0   17    1   12    0]\n",
      " [   0 1096    7    3    1    0    5    1   22    0]\n",
      " [  14   15  868   19   20    0   31   19   35   11]\n",
      " [   5    4   33  874    1    0   10   16   40   27]\n",
      " [   3    9    4    0  821    0   21    2   12  110]\n",
      " [  83   30    9  301   52    0   48   35  272   62]\n",
      " [  19    3   13    2   10    0  892    0   19    0]\n",
      " [   5   38   31    0   12    0    4  878    5   55]\n",
      " [  11   15   16   40    9    0   21   13  823   26]\n",
      " [  17   12   10   12   40    0    3   25   16  874]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91       980\n",
      "          1       0.90      0.97      0.93      1135\n",
      "          2       0.87      0.84      0.86      1032\n",
      "          3       0.70      0.87      0.77      1010\n",
      "          4       0.85      0.84      0.84       982\n",
      "          5       0.00      0.00      0.00       892\n",
      "          6       0.85      0.93      0.89       958\n",
      "          7       0.89      0.85      0.87      1028\n",
      "          8       0.66      0.84      0.74       974\n",
      "          9       0.75      0.87      0.80      1009\n",
      "\n",
      "avg / total       0.74      0.81      0.77     10000\n",
      "\n",
      "Accuracy\n",
      "0.8072\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train\n",
    "for _ in range(100):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    2    0    0    0    7    1    8    0]\n",
      " [   0 1102    2    4    1    1    4    0   21    0]\n",
      " [  13    2  892   18   12    0   17   23   42   13]\n",
      " [   6    1   21  890    1   34    6   14   22   15]\n",
      " [   3    8    4    0  866    1   13    1   15   71]\n",
      " [  22   14    6   37   19  684   23   13   64   10]\n",
      " [  19    3    4    1    6   16  899    0   10    0]\n",
      " [   5   21   35    2    9    0    1  910    6   39]\n",
      " [   8    9   11   16    7   18   15   12  865   13]\n",
      " [  15    8    5    9   30   16    1   17   13  895]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95       980\n",
      "          1       0.94      0.97      0.96      1135\n",
      "          2       0.91      0.86      0.89      1032\n",
      "          3       0.91      0.88      0.90      1010\n",
      "          4       0.91      0.88      0.90       982\n",
      "          5       0.89      0.77      0.82       892\n",
      "          6       0.91      0.94      0.92       958\n",
      "          7       0.92      0.89      0.90      1028\n",
      "          8       0.81      0.89      0.85       974\n",
      "          9       0.85      0.89      0.87      1009\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10000\n",
      "\n",
      "Accuracy\n",
      "0.8965\n"
     ]
    }
   ],
   "source": [
    "# learning rate at 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train\n",
    "for _ in range(500):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting how long the training runs seems to have the largest effect of any one element on the accuracy of the model. Setting the value to 10,000 gave resulted in the most accurate model so far (92.7%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the interaction of two variables\n",
    "In the initial testing, the following seemed to hold true:\n",
    "* Larger learning rates result in better scores. This may be the result of the smaller learning rates not being given enough runtime to reach the minimum\n",
    "* Batch sizes alone do not have a large result on the model's accuracy, but larger batch sizes seem to be slightly better\n",
    "* Increasing the number of batches run seems to improve the model (this may result in overtraining)\n",
    "\n",
    "In this next step, I will examine how adjustments to these variables interact with each other. Because the number of training steps seems to have the largest affect on the model, I will focus on adjustments which include adjustments to this variable.\n",
    "##### Learning Rate and Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 964    0    2    2    1    1    7    1    2    0]\n",
      " [   0 1108    4    5    0    2    4    2   10    0]\n",
      " [  14    1  926    7   16    3   13   13   31    8]\n",
      " [   2    0   25  926    1   16    3    9   18   10]\n",
      " [   2    2    6    0  918    0   11    2    4   37]\n",
      " [  10    3    7   35   11  758   14   11   35    8]\n",
      " [  13    3    5    2    8   10  912    1    4    0]\n",
      " [   3    7   27    5    9    0    0  944    5   28]\n",
      " [   4    4    5   16    8   17   11   13  892    4]\n",
      " [  12    5    3   11   20   12    0   13   10  923]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.92      0.90      0.91      1032\n",
      "          3       0.92      0.92      0.92      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.93      0.85      0.89       892\n",
      "          6       0.94      0.95      0.94       958\n",
      "          7       0.94      0.92      0.93      1028\n",
      "          8       0.88      0.92      0.90       974\n",
      "          9       0.91      0.91      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9271\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.75).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 10000 times\n",
    "for _ in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 963    0    1    2    1    1    9    1    2    0]\n",
      " [   0 1104    4    5    1    2    4    2   13    0]\n",
      " [  14    1  925    7   16    4   13   13   32    7]\n",
      " [   2    0   24  924    1   18    3   10   20    8]\n",
      " [   2    2    3    1  928    0   12    2    4   28]\n",
      " [  11    3    5   28   12  765   15   11   36    6]\n",
      " [  12    3    4    2    8   10  914    1    4    0]\n",
      " [   3    6   26    5    8    0    0  954    6   20]\n",
      " [   4    4    5   16    9   16   11   15  893    1]\n",
      " [  12    5    3   11   30   11    0   20   15  902]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.98      0.97      0.98      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.92      0.91      0.92      1010\n",
      "          4       0.92      0.95      0.93       982\n",
      "          5       0.93      0.86      0.89       892\n",
      "          6       0.93      0.95      0.94       958\n",
      "          7       0.93      0.93      0.93      1028\n",
      "          8       0.87      0.92      0.89       974\n",
      "          9       0.93      0.89      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9272\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.25).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 30000 times\n",
    "for _ in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 960    0    2    2    1    3    9    1    2    0]\n",
      " [   0 1106    2    6    1    2    4    2   12    0]\n",
      " [  14    1  910   12   15    2   14   18   39    7]\n",
      " [   3    1   20  922    1   23    2   10   19    9]\n",
      " [   2    1    2    1  926    0   13    2    4   31]\n",
      " [  10    3    6   37   14  753   15   11   35    8]\n",
      " [  14    3    5    2    9   11  908    1    5    0]\n",
      " [   5   11   25    5   10    0    0  943    3   26]\n",
      " [   4    7    5   21    9   16   11   15  883    3]\n",
      " [   9    6    3   11   36   16    0   13    9  906]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.97      0.97      0.97      1135\n",
      "          2       0.93      0.88      0.90      1032\n",
      "          3       0.90      0.91      0.91      1010\n",
      "          4       0.91      0.94      0.92       982\n",
      "          5       0.91      0.84      0.88       892\n",
      "          6       0.93      0.95      0.94       958\n",
      "          7       0.93      0.92      0.92      1028\n",
      "          8       0.87      0.91      0.89       974\n",
      "          9       0.92      0.90      0.91      1009\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n",
      "Accuracy\n",
      "0.9217\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.25).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 10000 times\n",
    "for _ in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    2    1    0    2    9    2    2    0]\n",
      " [   0 1110    4    4    0    1    5    2    9    0]\n",
      " [  11    2  932    7   16    5   12   12   29    6]\n",
      " [   3    0   22  920    0   21    5    9   21    9]\n",
      " [   2    3    5    0  918    0   12    2    7   33]\n",
      " [   8    2    5   28   14  773   13    8   34    7]\n",
      " [  13    3    5    2    7    9  917    1    1    0]\n",
      " [   3    7   28    4    9    1    0  944    5   27]\n",
      " [   4    6    4   16    7   16    9   10  899    3]\n",
      " [  11    5    2    7   21    9    1   13   14  926]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.92      0.90      0.91      1032\n",
      "          3       0.93      0.91      0.92      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.92      0.87      0.89       892\n",
      "          6       0.93      0.96      0.94       958\n",
      "          7       0.94      0.92      0.93      1028\n",
      "          8       0.88      0.92      0.90       974\n",
      "          9       0.92      0.92      0.92      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9301\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(1).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 10000 times\n",
    "for _ in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, based on the results from the previous section, it appears that increasing the learning rate and number of times the loop is run also improves the accuracy of the model (93% is the new highest accuracy). Presumably at some point the learning rate will become too large and negatively affect the result.\n",
    "\n",
    "##### Batch Size and Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    2    2    0    2    9    2    1    0]\n",
      " [   0 1110    4    4    0    2    4    2    9    0]\n",
      " [  12    1  929    7   18    6   10   13   29    7]\n",
      " [   2    0   24  924    0   18    4    9   19   10]\n",
      " [   2    2    4    1  924    0   11    2    4   32]\n",
      " [   8    3    3   31   12  768   15    9   36    7]\n",
      " [  12    3    4    2    8   12  915    1    1    0]\n",
      " [   3    7   27    4   10    1    0  951    4   21]\n",
      " [   4    6    4   19    7   18   11   15  888    2]\n",
      " [  12    5    2   11   25   11    1   14   12  916]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.92      0.91      0.92      1010\n",
      "          4       0.92      0.94      0.93       982\n",
      "          5       0.92      0.86      0.89       892\n",
      "          6       0.93      0.96      0.94       958\n",
      "          7       0.93      0.93      0.93      1028\n",
      "          8       0.89      0.91      0.90       974\n",
      "          9       0.92      0.91      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9287\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 10000 times\n",
    "for _ in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 961    0    2    2    1    1   10    1    2    0]\n",
      " [   0 1106    2    6    1    2    4    2   12    0]\n",
      " [  14    1  921   10   16    3   12   14   33    8]\n",
      " [   2    0   24  926    1   19    3    9   17    9]\n",
      " [   2    2    3    1  926    0   12    2    3   31]\n",
      " [  11    3    6   33   13  760   15   11   32    8]\n",
      " [  12    3    5    2    8   11  913    1    3    0]\n",
      " [   3    7   27    5    8    0    0  952    5   21]\n",
      " [   4    4    5   17    9   19   11   14  889    2]\n",
      " [  11    5    3   11   30   14    0   15   11  909]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.98      0.97      0.98      1135\n",
      "          2       0.92      0.89      0.91      1032\n",
      "          3       0.91      0.92      0.92      1010\n",
      "          4       0.91      0.94      0.93       982\n",
      "          5       0.92      0.85      0.88       892\n",
      "          6       0.93      0.95      0.94       958\n",
      "          7       0.93      0.93      0.93      1028\n",
      "          8       0.88      0.91      0.90       974\n",
      "          9       0.92      0.90      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9263\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 10000 times\n",
    "for _ in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 960    0    2    2    1    3    9    1    2    0]\n",
      " [   0 1105    2    6    1    2    4    2   13    0]\n",
      " [  15    1  910   13   15    2   15   16   38    7]\n",
      " [   3    1   20  922    1   24    2   10   17   10]\n",
      " [   2    1    3    1  914    0   15    2    4   40]\n",
      " [  11    3    5   38   13  755   15   10   34    8]\n",
      " [  14    3    4    2    8   12  911    1    3    0]\n",
      " [   5   11   25    5    9    0    0  944    3   26]\n",
      " [   4    6    5   22    9   20   12   14  879    3]\n",
      " [   9    6    3   12   30   16    0   13    8  912]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.97      0.97      0.97      1135\n",
      "          2       0.93      0.88      0.91      1032\n",
      "          3       0.90      0.91      0.91      1010\n",
      "          4       0.91      0.93      0.92       982\n",
      "          5       0.91      0.85      0.87       892\n",
      "          6       0.93      0.95      0.94       958\n",
      "          7       0.93      0.92      0.93      1028\n",
      "          8       0.88      0.90      0.89       974\n",
      "          9       0.91      0.90      0.91      1009\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n",
      "Accuracy\n",
      "0.9212\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 10000 times\n",
    "for _ in range(5000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(500)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Make everything bigger\" seems like a crude approach toward improving the model, and so far none of the adjustments have created more than a couple percentage points of improvement in the model, but it is the best approach I have, based on the results of other testing.\n",
    "\n",
    "##### Putting It All Together\n",
    "The following models involve adjustment of all three parameters, using my best guesses based on the previous results. Using the MLPClassifier, the highest accuracy was 96.8%, and so far none of the tensorflow models have come close to reaching it (the highest accuracy in the tensorflow models so far has been 93.0%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 961    0    2    2    0    2   10    2    1    0]\n",
      " [   0 1109    4    4    0    2    5    2    9    0]\n",
      " [  10    2  933   10   16    4   11   13   27    6]\n",
      " [   2    0   22  931    0   15    5    8   16   11]\n",
      " [   2    2    4    1  923    0   11    2    4   33]\n",
      " [   8    3    5   33   15  771   13    7   31    6]\n",
      " [  13    3    6    2    7   10  915    1    1    0]\n",
      " [   3    6   27    6    9    1    0  950    4   22]\n",
      " [   4    6    5   20    8   19   10   14  884    4]\n",
      " [  12    5    2    8   22    9    1   14   12  924]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.92      0.90      0.91      1032\n",
      "          3       0.92      0.92      0.92      1010\n",
      "          4       0.92      0.94      0.93       982\n",
      "          5       0.93      0.86      0.89       892\n",
      "          6       0.93      0.96      0.94       958\n",
      "          7       0.94      0.92      0.93      1028\n",
      "          8       0.89      0.91      0.90       974\n",
      "          9       0.92      0.92      0.92      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9301\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(1).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 30000 times\n",
    "for _ in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, despite seeing that batch size increase slightly improves the model in earlier testing, this resulted in the exact same accuracy (out to four decimal places) as this same setup with 1/10th the batch size resulted in earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    2    2    0    2    9    1    2    0]\n",
      " [   0 1110    4    3    0    2    4    2   10    0]\n",
      " [  12    1  925    7   16    6   13   13   31    8]\n",
      " [   2    0   24  925    1   19    3    9   18    9]\n",
      " [   2    2    3    1  924    0   12    2    4   32]\n",
      " [   9    3    4   31   12  766   15   11   34    7]\n",
      " [  12    3    4    2    8   11  914    1    3    0]\n",
      " [   3    7   26    5    8    0    0  953    5   21]\n",
      " [   4    4    5   17    8   19   11   14  890    2]\n",
      " [  12    5    3   11   26   12    0   15   11  914]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.92      0.92      0.92      1010\n",
      "          4       0.92      0.94      0.93       982\n",
      "          5       0.92      0.86      0.89       892\n",
      "          6       0.93      0.95      0.94       958\n",
      "          7       0.93      0.93      0.93      1028\n",
      "          8       0.88      0.91      0.90       974\n",
      "          9       0.92      0.91      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9283\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(.25).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 30000 times\n",
    "for _ in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 963    0    2    2    0    2    8    2    1    0]\n",
      " [   0 1109    4    4    0    2    4    2    9    1]\n",
      " [  11    4  926   13   15    3   13   10   31    6]\n",
      " [   2    0   20  932    0   16    3    6   22    9]\n",
      " [   2    4    4    1  919    0   13    2    5   32]\n",
      " [   8    1    5   30   13  776   11    7   35    6]\n",
      " [  12    3    5    2    7   17  909    1    2    0]\n",
      " [   3    7   24    6    8    1    0  951    4   24]\n",
      " [   4    6    3   19    6   21    7   12  891    5]\n",
      " [  11    5    2    9   21   10    1   16   14  920]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.97      0.98      0.98      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.92      0.92      0.92      1010\n",
      "          4       0.93      0.94      0.93       982\n",
      "          5       0.92      0.87      0.89       892\n",
      "          6       0.94      0.95      0.94       958\n",
      "          7       0.94      0.93      0.93      1028\n",
      "          8       0.88      0.91      0.90       974\n",
      "          9       0.92      0.91      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9296\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(1.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 30000 times\n",
    "for _ in range(50000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 959    0    2    2    0    2   11    2    2    0]\n",
      " [   0 1108    4    4    0    2    5    2    9    1]\n",
      " [   9    4  935    9   15    4   12   10   28    6]\n",
      " [   2    0   22  921    0   23    4    8   19   11]\n",
      " [   2    2    5    0  917    0   12    2    5   37]\n",
      " [   8    1    5   28   14  775   12    7   35    7]\n",
      " [  11    3    5    2    7   12  916    1    1    0]\n",
      " [   3    6   27    6    9    1    0  944    4   28]\n",
      " [   4    6    5   17    7   21    8    9  891    6]\n",
      " [  12    5    2    8   19    8    1   11   13  930]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.92      0.91      0.91      1032\n",
      "          3       0.92      0.91      0.92      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.91      0.87      0.89       892\n",
      "          6       0.93      0.96      0.94       958\n",
      "          7       0.95      0.92      0.93      1028\n",
      "          8       0.88      0.91      0.90       974\n",
      "          9       0.91      0.92      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9296\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(1.5).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 30000 times\n",
    "for _ in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears increasing the learning rate to 1.5 reduces the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 962    0    2    1    0    2    9    2    2    0]\n",
      " [   0 1108    4    4    0    2    5    2    9    1]\n",
      " [  14    2  934    9   16    0   11   13   27    6]\n",
      " [   3    0   22  928    0   14    5    8   19   11]\n",
      " [   2    2    5    0  919    0   12    2    4   36]\n",
      " [  10    1    5   32   15  767   12    8   35    7]\n",
      " [  12    3    6    2    8    8  917    1    1    0]\n",
      " [   3    6   26    4    9    1    0  954    4   21]\n",
      " [   5    5    5   19    9   15    9   15  889    3]\n",
      " [  12    5    2    8   21    8    1   21   11  920]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.92      0.91      0.91      1032\n",
      "          3       0.92      0.92      0.92      1010\n",
      "          4       0.92      0.94      0.93       982\n",
      "          5       0.94      0.86      0.90       892\n",
      "          6       0.93      0.96      0.95       958\n",
      "          7       0.93      0.93      0.93      1028\n",
      "          8       0.89      0.91      0.90       974\n",
      "          9       0.92      0.91      0.91      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.9298\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(1.25).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 30000 times\n",
    "for _ in range(30000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[ 961    0    2    2    0    2   10    2    1    0]\n",
      " [   0 1110    4    4    0    1    5    2    9    0]\n",
      " [  11    2  930   10   16    3   12   13   29    6]\n",
      " [   2    0   21  930    0   16    4    8   19   10]\n",
      " [   2    2    4    1  921    0   12    2    5   33]\n",
      " [   8    1    5   34   15  769   13    7   34    6]\n",
      " [  12    3    6    2    7    9  917    1    1    0]\n",
      " [   3    6   26    6    9    1    0  947    4   26]\n",
      " [   4    6    4   20    7   16    9   12  891    5]\n",
      " [  12    5    2    9   22    7    1   14   13  924]]\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.93      0.90      0.91      1032\n",
      "          3       0.91      0.92      0.92      1010\n",
      "          4       0.92      0.94      0.93       982\n",
      "          5       0.93      0.86      0.90       892\n",
      "          6       0.93      0.96      0.94       958\n",
      "          7       0.94      0.92      0.93      1028\n",
      "          8       0.89      0.91      0.90       974\n",
      "          9       0.91      0.92      0.92      1009\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "Accuracy\n",
      "0.93\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(1.25).minimize(cross_entropy)\n",
    "\n",
    "# make new session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# train - run the training step 30000 times\n",
    "for _ in range(50000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(500)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "## using sklearn to get metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "predictions = tf.argmax(y, 1)\n",
    "known = tf.argmax(y_,1)\n",
    "predict, actual = sess.run([predictions, known], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "# print confusion matrix, classificiation report, accuracy\n",
    "confusion = confusion_matrix(actual, predict)\n",
    "classification_report = classification_report(actual, predict)\n",
    "accuracy = accuracy_score(actual, predict)\n",
    "print('Confusion matrix')\n",
    "print(confusion)\n",
    "print('\\nClassification report')\n",
    "print(classification_report)\n",
    "print ('Accuracy')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the highest accuracy I was able to obtain was 93%, and the way I did it seems a little crude.\n",
    "I strongly suspect that my results were largely the result of being new to tensorflow, and if I had a better understanding of the tools available, the tensorflow models might have beaten the scikit-learn models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD-comments\n",
    "\n",
    "Excellent Analysis.  You are right about tensorflow and the quality of these networks.  It is possible to make better analysis of MNIST with tensorflow using specialized types of networks (Convolutional NN) but for a small problem like this ~97% accuracy for a few minutes training is a really good result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
